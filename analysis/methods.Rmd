---
title: "Methods"
author: "Tina Lasisi"
date: "`r format(Sys.time(), '%Y-%m-%d %H:%M:%S')`"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---


# Long-Range Familial Searching

## Coop & Edge 2019

Coop & Edge ([2019](https://www.biorxiv.org/content/10.1101/531384v1.full)) use a population genetics approach to estimate the likelihood of finding a genetic relative in a database. They assumes that two individuals are related if they share a certain number of genetic blocks, which is determined by the degree of relatedness (e.g. first cousin, second cousin, etc.). Using this assumption, they calculates the expected number of blocks shared between two individuals of a given degree of relatedness based on the size of the genetic database and the population size. They then uses the Poisson distribution to estimate the probability of finding at least one relative of a given degree of relatedness in a database of a certain size.

The original code can be found [here](https://github.com/tinalasisi/POPFORGE/blob/master/data/Coop_cousins_vs_database_size.R). 

Below is an adaptation of the code for demonstration purposes with annotations for clarification.

### Population and Database Size Estimation

In the code chunk below, we make several assumptions about the population size of possible ancestors based on data from the US census. The assumptions used in the analysis include an average time of 30 years between generations, and a population size for the relevant time period calculated as the size of the population in 1950, adjusted for the number of generations separating the individuals in question. 

Additionally, it is assumed that about half of individuals in the population are potentially parents, and 90% of those individuals have children. The minimum population size is set to 1 million for populations smaller than that, and a vector of database sizes is created to test the expected number of cousins in a database of various sizes.

```{r setup, fig.height=6, fig.width=8}
# Load necessary packages
library(wesanderson) # for color palettes

# Set path to the data file
path <- "./data/"
savepath <- "./output/"

# Set up vector for cousin degree
p <- c(1:8) 

# Set up initial population size
N <- 76e6 

# Read in data on US population sizes by year
US_pop <- read.csv(paste(path, "US_popsize.csv", sep = ""))

# Calculate number of grandparents by generation
p_grandpar_gen <- 1950 - 30 * (p + 1)

# Determine which years match the grandparents' generation
these.years <- match(p_grandpar_gen, US_pop$Year)

# Get population sizes by year for grandparents' generation
US_Ns <- US_pop$Population[these.years]

# Scale population size down by 50% (assumed number of potential parents) and 90% of those have children 
N <- US_Ns
N <- N * 0.5 * 0.9 

# Set minimum population size for small populations
N[US_Ns < 1e6] <- 1e6 # is this in the correct order? 

# Set up vector of database sizes to test
DB.sizes <- c(1e6, 5e6, 10e6)

# Set color palette for graphs
my.cols <- wes_palette("Darjeeling1")
```


### Probability of p-th degree cousin and number of p-th degree cousins

The code below calculates the probability of having at least one p-th cousin in the database and the expected number of p-th cousins in the sample for different database sizes. The first plot shows the probability of having at least one p-th cousin in the database based on the degree of relatedness and the size of the database. The second plot shows the expected number of p-th cousins in the sample for different database sizes.

```{r plt-cousins, fig.height=6, fig.width=8, fig.cap="The plot above displays the probability of having at least one p-th cousin in a genetic database and the expected number of p-th cousins in a database. The left plot shows the probability of finding at least one p-th cousin in a database of a given size, and the right plot shows the expected number of p-th cousins in a database of a given size based on the number of genetic blocks shared."}

layout(t(1:2))

# Plot probability of having at least one p-th cousin in database
plot(c(1, 8), c(0, 1), type = "n", ylab = "Probability of at least one p-th cousin in database", xlab = "p (degree of cousin)")
sapply(1:length(DB.sizes), function(i) {
  DB.size <- DB.sizes[i]
  prob.no.rellys <- exp(-2^(2*p - 2) * DB.size / N)
  points(p, 1 - prob.no.rellys, type = "b", col = my.cols[i], pch = 19, lwd = 1.5)
})
legend(x = "bottomright", legend = c("Database size (Millions) =", format(DB.sizes / 1e6, dig = 1)), col = c(NA, my.cols), pch = 19)

# Plot of expected number of p-th cousins in sample
plot(c(1,8),c(0,1000),type="n",ylab="Expected number of p-th cousins in database",xlab="p.(degree of cousin)")
sapply(1:length(DB.sizes),function(i){

    num.cousins<-4^(p)*DB.sizes[i]/(N/2)
    points(p,num.cousins,type="b",col=my.cols[i],lwd=1.5,pch=19)
   # points(p,4^(p),type="b",col="black")
})


```

### Probability of a genetically detectable cousin

Below, we calculate the expected number of shared blocks of genetic material between cousins of varying degrees of relatedness. This is important because the probability of detecting genetic material that is shared between two individuals decreases as the degree of relatedness between them decreases. The code uses a Poisson distribution assumption to estimate the probability of two cousins sharing at least one, two, or three blocks of genetic material, based on the expected number of shared blocks of genetic material calculated from previous research.


```{r genetic-blocks}

# The variable 'meiosis' represents the number of meiosis events between cousins, where 'p' is the degree of relatedness (i.e. p = 1 for first cousins, p = 2 for second cousins, etc.)
meiosis <- p + 1

## Expected number of blocks shared between cousins
# 'E.num.blocks' is the expected number of blocks of shared genetic material between cousins based on the degree of relatedness and the number of meiosis events between them. This value is calculated based on previous research and is not calculated in this code.
E.num.blocks <- 2 * (33.8 * (2 * meiosis) + 22) / (2^(2 * meiosis - 1))

## Use Poisson assumption
# 'Prob.genetic' is the probability of two cousins sharing at least one block of genetic material based on the expected number of shared blocks calculated in the previous step. The calculation uses a Poisson distribution assumption.
Prob.genetic <- 1 - exp(-E.num.blocks)

# 'prob.g.e.2.blocks' is the probability of two cousins sharing at least two blocks of genetic material based on the expected number of shared blocks calculated in the previous step. The calculation uses a Poisson distribution assumption.
prob.g.e.2.blocks <- 1 - sapply(E.num.blocks, function(expected.num) {sum(dpois(0:1, expected.num))})

# 'prob.g.e.3.blocks' is the probability of two cousins sharing at least three blocks of genetic material based on the expected number of shared blocks calculated in the previous step. The calculation uses a Poisson distribution assumption.
prob.g.e.3.blocks <- 1 - sapply(E.num.blocks, function(expected.num) {sum(dpois(0:2, expected.num))})


```

```{r plt-genetic-blocks, fig.cap="Probabilities of detecting a genetic cousin in a database based on shared genomic blocks. Blue lines represent cousins with at least one genomic block, orange dotted and red lines represent cousins with at least two and three genomic blocks, respectively. The legend specifies the type of cousin being represented by each line."}

## Plot for number of shared blocks with p-th degree cousins
# Set layout of plot
layout(t(1))

# Set color palette for plot
my.cols2<-wes_palette("FantasticFox1")[3:5]

# Create a blank plot with labeled axes
plot(c(1,8),c(0,1),type="n",ylab="Probability p-th cousin \"detectable\"",xlab="p.(degree of cousin)")

# Add points for probability of detecting pth cousin with genomic blocks using colors from my.cols2
points(p,Prob.genetic,col=my.cols2[1],pch=19,type="b",lwd=2)
points(p,prob.g.e.2.blocks,col=my.cols2[2],pch=19,type="b",lwd=2)
points(p,prob.g.e.3.blocks,col=my.cols2[3],pch=19,type="b",lwd=2)

# Add a legend to the plot
legend(x="topright",legend=c("Cousins (w. >0 genomic blocks)","Cousins (w. >1 genomic blocks)","Cousins (w. >2 genomic blocks)"),col=my.cols2[1:3],lty=1)

```


```{r plt-num-cousins, fig.cap="This figure shows the expected number of genetic relatives of degree p in a database of a given size. The x-axis represents the degree of relatedness, while the y-axis represents the expected number of genetic relatives. Each line represents a different database size."}

## Plot for expected number of p-th degree cousins in a given database

# Set the layout of the plot
layout(t(1))

# Create a plot with the y-axis ranging from 0 to 350 and the x-axis ranging from 1 to 8, labeled as "Expected number of genetic p-th cousins in database" and "p. (degree of cousin)", respectively
plot(c(1,8),c(0,350),type="n",ylab="Expected number of genetic p-th cousins in database",xlab="p. (degree of cousin)")

# For each database size, calculate the expected number of genetic cousins based on the size of the database, the total number of individuals in the population, and the expected number of blocks of shared genetic material between cousins. Multiply the number of expected genetic cousins by the probability of sharing at least three blocks of genetic material with a cousin, and plot the result as a line on the plot. Repeat this for each database size.
sapply(1:length(DB.sizes),function(i){

    num.cousins<-4^(p)*DB.sizes[i]/(N/2)
    points(p,num.cousins*prob.g.e.3.blocks,type="b",lty=1,col=my.cols[i])

})

# Create a legend for the plot that explains what each line represents, including the legend for the database size
my.leg <- c(c("Genetic Cousins", ">2 blocks"), c("Database size (Millions)=", format(DB.sizes/1e6, dig=1)))
legend(x="topright",legend=my.leg,col=c(NA,rep("black",1),NA,my.cols),lty=c(NA,1:2,rep(NA,3)),pch=c(rep(NA,3),rep(19,3)))


```


## Erlich et al 2018

The authors carried out a detailed investigation to find out how likely it is to identify a person using long-range familial searches with genetic data from direct-to-consumer databases. The goal was to understand the privacy risks related to DNA data and its consequences for law enforcement and research studies. To do this, the authors created various mathematical models that considered factors like the size of the population, the size of the database, and the criteria for finding matches. They also took into account different types of relationships, such as regular cousins and once-removed cousins.

The R code provided with the study includes functions that implement these models and methods, which allows users to assess the likelihood of identifying a person through long-range familial searches. The authors used population genetics models to estimate the probabilities of finding relatives with specific amounts of shared DNA, known as identity by descent (IBD) segments. These models were based on assumptions like uniform population growth, no inbreeding, and random sampling, providing a rough guideline for estimating identification probabilities.


```{r erlich-functions}

# Define genome size and number of chromosomes
genome_size = 35 
num_chrs = 22

# Function to calculate the probability of a match for direct relatives
p_match = function(g, m, min_num_seg)
{
  m = m / 100 # Convert m from cM to fraction
  f = exp(-2 * g * m) / 2^(2 * g - 2) # Calculate f value
  pr = 1 - pbinom(min_num_seg - 1, num_chrs + genome_size * 2 * g, f) # Calculate probability
  return(pr)
}

# Function to calculate the probability of a match for once removed relatives
p_match_or = function(g, m, min_num_seg) 
{
  m = m / 100 # Convert m from cM to fraction
  f = exp(-(2 * g + 1) * m) / 2^(2 * g - 1) # Calculate f value
  pr = 1 - pbinom(min_num_seg - 1, num_chrs + genome_size * (2 * g + 1), f) # Calculate probability
  return(pr)
}

# Function to calculate the coverage of the database
coverage = function(Ks, maxg, N_pop, r, m, min_num_seg, min_num_rel, rep_direct = rep(1, 10), rep_or = rep(1, 10))
{
  N = N_pop / 2 # Convert population size to couple size
  pr_succ = length(Ks) # Initialize the vector of probabilities of success
  
  # Loop through database sizes
  for (i in 1:length(Ks)) 
  {
    K = Ks[i] # Current database size
    K_same = round(K * (r / 2) / (1 + r / 2)) # Calculate the number of direct relatives
    K_or = round(K * 1 / (1 + r / 2)) # Calculate the number of once removed relatives
    
    # Initialize vectors for probability calculations
    p_no_coal = numeric(maxg) 
    p_coal = numeric(maxg)
    p_no_coal_or = numeric(maxg) 
    p_coal_or = numeric(maxg)
    Ns = N * (r / 2)^(-(1:(maxg + 1))) # Calculate Ns values
    tot_p = 0
    tot_p_or = 0
    
    # Loop through generations
    for (g in 1:maxg)
    {
      f = 2^(2 * g - 2) / Ns[g] # Calculate f value for direct relatives
      f_or = 2^(2 * g - 1) / Ns[g + 1] # Calculate f value for once removed relatives
      
      # Update probabilities
      if (g > 1) {
        p_coal[g] = p_no_coal[g - 1] * f
        p_no_coal[g] = p_no_coal[g - 1] * (1 - f)
        p_coal_or[g] = p_no_coal_or[g - 1] * f_or
        p_no_coal_or[g] = p_no_coal_or[g - 1] * (1 - f_or)
      } else {
        p_coal[g] = f 
        p_no_coal[g] = 1 - f 
        p_coal_or[g] = f_or 
        p_no_coal_or[g] = 1 - f_or
      }
      
      # Update total probabilities
      tot_p = tot_p + p_coal[g] * p_match(g, m, min_num_seg) * rep_direct[g] 
      if (g < maxg) {
        tot_p_or = tot_p_or + p_coal_or[g] * p_match_or(g, m, min_num_seg) * rep_or[g]
      } 
    }

    # Calculate probability of no success
    pr_no_succ = 0
    for (n in 0:(min_num_rel - 1)) 
    {
      for (n_or in 0:n) 
      {
        pr_no_succ = pr_no_succ + dbinom(n_or, K_or, tot_p_or) * dbinom(n - n_or, K_same, tot_p)
      }
    }
    
    # Calculate the probability of success
    pr_succ[i] = 1 - pr_no_succ
  }
  
  return(pr_succ)
}

# Ks: A vector of database sizes
# maxg: Maximum relatedness to consider (1: sibs, 2: 1st cousins, 3: 2nd cousins...)
# N: Population size

# r: Mean number of children per mating pair (=per family), so 2 for a constant size population, >2 for expanding population, <1 for contracting population
# m: Maximum length in cM of a detectable segment
# min_num_seg: Minimum number of segments to declare a match
# min_num_rel: Minimum number of detected matches (=relatives)
# to declare success of identification


```


```{r erlich-fig1b-calcs}

N = 250000000 #population size
num_K = 10000 #number of data points between 0 to 1 
m = 6 #minimal cM
min_num_seg = 2 #number of segments
r = 2.5 #number of kids per couple
Ks = round(seq(from=N/num_K,to=N,length.out=num_K))

N_pop = N # added by Tina to run below

c1 = coverage(Ks,maxg=2,N_pop,r,m,min_num_seg=2,min_num_rel=1) 
c2 = coverage(Ks,maxg=3,N_pop,r,m,min_num_seg=2,min_num_rel=1) 
c3 = coverage(Ks,maxg=4,N_pop,r,m,min_num_seg=2,min_num_rel=1) 
c4 = coverage(Ks,maxg=5,N_pop,r,m,min_num_seg=2,min_num_rel=1)

```

```{r erlich-fig1b-plot}

library(ggplot2)
# Combine the data points into a single data frame
plot_data <- data.frame(Ks = rep(Ks, 4),
                        Coverage = c(c1, c2, c3, c4),
                        Relationship = factor(rep(c("1C", "2C", "3C", "4C"), each = num_K)))

# Calculate database size as a proportion of the population size
plot_data$Ks_proportion <- plot_data$Ks / N

# Create a ggplot2 plot
p <- ggplot(plot_data, aes(x = Ks_proportion, y = Coverage, color = Relationship, group = Relationship)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = seq(0, 0.05, 0.01), limits = c(0, 0.05)) +
  labs(title = "Long-range Familial Search Coverage",
       x = "Database Size / Population Size",
       y = "Probability of a Match",
       color = "Cousin Relationship") +
  theme_minimal() +
  theme(legend.position = "none") +
  geom_text(data = subset(plot_data, Ks_proportion == 0.007), aes(label = Relationship), vjust = 3)

# Display the plot
p



```


Differences in the assumptions between the two models are mainly in the following:

Population size: Coop and Edge’s model uses data on US population sizes by year to estimate the number of grandparents by generation, whereas Erlich et al assume a constant population size with a mean number of children per couple  equal to 2.5.

Genomic segments inheritance: Coop and Edge’s model calculates the expected number of shared blocks of genetic material between cousins of varying degrees of relatedness, and it uses a Poisson distribution assumption to estimate the probability of two cousins sharing at least one, two, or three blocks of genetic material. Ehrlich et al assume that genomic segments are inherited independently of each other and models the probability of a match using a binomial distribution.


