---
title: "Analyses"
author: "Tina Lasisi"
date: "`r format(Sys.time(), '%Y-%m-%d %H:%M:%S')`"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---


```{r setup}
# Load necessary packages
library(wesanderson) # for color palettes
library(tidyverse) #data wrangling etc
library(RColorBrewer)

# Set path to the data file
path <- file.path(".", "data")
savepath <- file.path(".", "output")

# Set up vector for cousin degree
p <- c(1:8) 

# Set up initial population size
N <- 76e6 # what does this do?

```


```{r}
# Read in data on US population sizes by year
US_pop_fp <- file.path(path, "est-pop-combo.csv")
US_pop_coop_fp <- file.path(path, "US_popsize.csv")

# Read in data on US population sizes by year
pop1 <- read.csv(US_pop_fp) %>% 
  select(Year, Black, White, Total)

pop2 <- read.csv(US_pop_coop_fp) %>%
  rename(Coop = Population)

pop <- left_join(pop1, pop2)

# Set up vector of database sizes to test
DB.sizes <- c(1e6, 5e6, 10e6)
# DB.sizes <- c(0.05*1e6, 0.15*1e6, 0.50*1e6, 1e6, 5e6, 10e6)

# Set color palette for graphs
my.cols <- wes_palette("Darjeeling1")
# my.cols <- brewer.pal(n = 6, name = "Dark2")

# set starting generation
start_gen <- 1950

```


```{r func-calc-N}

# Calculate number of grandparents by generation
calc_grandparent_gen <- function(year, p = c(1:8)) {
  yrs_grandparent_gen <- year - 30 * (p + 1)
  return(yrs_grandparent_gen)
}


# Define a function to calculate final population sizes based on input data file and generation of grandparents
calc_final_N <- function(pop=pop, start_gen=start_gen) {

  # Calculate number of grandparents by generation
  yrs_grandpar_gen <- calc_grandparent_gen(start_gen)

  # Get population sizes by year for grandparents' generation
  gp_Ns <- pop %>% 
    filter(Year %in% yrs_grandpar_gen)

  # Scale population size down by 50% (assumed number of potential parents) and 90% of those have children + set minimum for populations
  # scaled_N <- gp_Ns
  scaled_N <- gp_Ns %>%
  mutate(across(!Year, ~ case_when(. * 0.5 * 0.9 < 1e6 ~ 1e6,
                                   TRUE ~ . * 0.5 * 0.9)))

  return(scaled_N)
}


```


```{r calc-final-N}

N <- calc_final_N(pop, start_gen) %>% 
  arrange(desc(Year))

# N2 <- calc_final_N(pop2, start_gen)


```

```{r pop-size}

# Define the population sizes and names
populations <- N %>% 
  pivot_longer(-Year, names_to = "Population", values_to = "N") %>% 
  mutate(Population = factor(Population,
                             levels = c("Black", "White", "Total", "Coop")))

# Create a ggplot object to visualize population sizes
pop_size_plot <- ggplot(populations, aes(x = Population, y = N)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(x = "Population", y = "Population size") +
  theme_minimal() +
  facet_wrap(~Year, scales = "free")

# Display the plot
pop_size_plot

```



## Probability of p-th degree cousin 


```{r df-cousinsprob}


calc_prob <- function(p, DB.sizes, N) {
  pop_columns <- N[, -1, drop = FALSE]

  results_df <- tibble(Population = character(), p.degree = numeric(), DB.size = numeric(), Prob = numeric())

  for (pop_name in colnames(pop_columns)) {
    pop_vector <- pop_columns[[pop_name]]

    for (db_size in DB.sizes) {
      prob.no.rellys <- exp(-2^(2 * p - 2) * db_size / pop_vector)
        prob.rel <- 1 - prob.no.rellys

        results_df <- rbind(results_df, tibble(Population = pop_name, p.degree = p, DB.size = db_size, Prob = prob.rel))
    }
  }

  return(results_df)
}




plt_df <- calc_prob(p, DB.sizes, N) %>% 
  mutate(Population = factor(Population,
                             levels = c("Black", "White", "Total", "Coop")))
```


```{r plt-cousinsprob, fig.cap="Probability of finding at least one p-th degree cousin in a database of varying sizes for different populations. Each panel represents a population, and the lines within each panel correspond to different database sizes"}

ggplot_prob <- function(data, my.cols=my.cols) {
  # Group data by Population and DB.size
  data_grouped <- data %>%
    group_by(Population, DB.size)

  plot <- ggplot(data_grouped, aes(x = p.degree, y = Prob, color = factor(DB.size), group = factor(DB.size))) +
    geom_point() +
    geom_line() +
    scale_color_manual(values = my.cols, name = "Database size\n(Millions)",
                       labels = format(unique(data$DB.size) / 1e6, dig = 1)) +
    labs(x = "p (degree of cousin)", y = "Probability of at least one p-th cousin in database") +
    theme_minimal() +
    facet_wrap(~ Population, labeller = labeller(Population = as_labeller(function(x) x))) +
    scale_x_continuous(breaks = 1:8) + # Show every value from 1 to 8 on the x-axis
    scale_y_continuous(limits = c(0.0, 1.0)) # Set y-axis limits to 0.0 and 1.0

  return(plot)
}


ggplot_prob(plt_df, my.cols)



```



```{r plt-diffs, fig.cap="Differences between populations in the probability of finding at least one p-th degree cousin in a database of varying sizes. Each panel represents a population, and the lines within each panel correspond to different database sizes"}

# generate ggplot object with populations in different colors


ggplot_prob_combined <- function(data){
  palette <- brewer.pal(n = length(unique(data$Population)), "Dark2")
  
  
  data <- data %>%
    mutate(DB.size.formatted = factor(scales::label_number(scale = 1/1e6, accuracy = 1, suffix = " Million")(DB.size)))
  
  plot <- ggplot(data, aes(x = p.degree, y = Prob, color = Population, group = interaction(Population, DB.size.formatted))) +
    geom_point() +
    geom_line() +
    scale_color_manual(values = palette, name = "Population") +
    labs(x = "p (degree of cousin)", y = "Probability of at least one p-th cousin in database") +
    theme_minimal() +
    facet_wrap(~DB.size.formatted)
  
  return(plot)
}

ggplot_prob_combined(plt_df)


```



## Number of p-th degree cousins

```{r df-numcousins, fig.cap="Expected number of p-th degree cousins in databases of varying sizes for different populations. Each panel represents a population, and the lines within each panel correspond to different database sizes"}
calc_cousins <- function(p, DB.sizes, N) {
  pop_columns <- N[, -1, drop = FALSE]

  results_df <- tibble(Population = character(), p.degree = numeric(), DB.size = numeric(), Num_Cousins = numeric())

  for (pop_name in colnames(pop_columns)) {
    pop_vector <- pop_columns[[pop_name]]

    for (db_size in DB.sizes) {
      num_cousins <- 4^(p) * db_size / (pop_vector / 2)

      results_df <- rbind(results_df, tibble(Population = pop_name, p.degree = p, DB.size = db_size, Num_Cousins = num_cousins))
    }
  }

  return(results_df)
}

plt_numcousins_df <- calc_cousins(p, DB.sizes, N) %>% 
  mutate(Population = factor(Population,
                             levels = c("Black", "White", "Total", "Coop")))

```

```{r plt-numcousins}

ggplot_cousins <- function(data, my.cols=my.cols) {
  # Group data by Population and DB.size
  data_grouped <- data %>%
    group_by(Population, DB.size)

  plot <- ggplot(data_grouped, aes(x = p.degree, y = Num_Cousins, color = factor(DB.size), group = factor(DB.size))) +
    geom_point() +
    geom_line() +
    scale_color_manual(values = my.cols, name = "Database size\n(Millions)",
                       labels = format(unique(data$DB.size) / 1e6, dig = 1)) +
    labs(x = "p (degree of cousin)", y = "Number of p-th degree cousins in database") +
    theme_minimal() +
    facet_wrap(~ Population, labeller = labeller(Population = as_labeller(function(x) x))) +
    scale_x_continuous(breaks = 1:8) + # Show every value from 1 to 8 on the x-axis
    scale_y_continuous(limits = c(0, max(data$Num_Cousins))) # Set y-axis limits to 0 and maximum number of cousins

  return(plot)
}

ggplot_cousins(plt_numcousins_df, my.cols)

```


## Probability of a genetically detectable cousin

Below, we calculate the expected number of shared blocks of genetic material between cousins of varying degrees of relatedness. This is important because the probability of detecting genetic material that is shared between two individuals decreases as the degree of relatedness between them decreases. The code uses a Poisson distribution assumption to estimate the probability of two cousins sharing at least one, two, or three blocks of genetic material, based on the expected number of shared blocks of genetic material calculated from previous research.


```{r genetic-blocks}

# The variable 'meiosis' represents the number of meiosis events between cousins, where 'p' is the degree of relatedness (i.e. p = 1 for first cousins, p = 2 for second cousins, etc.)
meiosis <- p + 1

## Expected number of blocks shared between cousins
# 'E.num.blocks' is the expected number of blocks of shared genetic material between cousins based on the degree of relatedness and the number of meiosis events between them. This value is calculated based on previous research and is not calculated in this code.
E.num.blocks <- 2 * (33.8 * (2 * meiosis) + 22) / (2^(2 * meiosis - 1))

## Use Poisson assumption
# 'Prob.genetic' is the probability of two cousins sharing at least one block of genetic material based on the expected number of shared blocks calculated in the previous step. The calculation uses a Poisson distribution assumption.
Prob.genetic <- 1 - exp(-E.num.blocks)

# 'prob.g.e.2.blocks' is the probability of two cousins sharing at least two blocks of genetic material based on the expected number of shared blocks calculated in the previous step. The calculation uses a Poisson distribution assumption.
prob.g.e.2.blocks <- 1 - sapply(E.num.blocks, function(expected.num) {sum(dpois(0:1, expected.num))})

# 'prob.g.e.3.blocks' is the probability of two cousins sharing at least three blocks of genetic material based on the expected number of shared blocks calculated in the previous step. The calculation uses a Poisson distribution assumption.
prob.g.e.3.blocks <- 1 - sapply(E.num.blocks, function(expected.num) {sum(dpois(0:2, expected.num))})


```



### General

```{r plt-genetic-blocks, fig.cap="Probabilities of detecting a genetic cousin in a database based on shared genomic blocks."}


# Create a data frame for the plot
genetic_blocks_df <- data.frame(p = p,
                                Prob.genetic = Prob.genetic,
                                prob.g.e.2.blocks = prob.g.e.2.blocks,
                                prob.g.e.3.blocks = prob.g.e.3.blocks)

# Pivot the data frame into a long format
genetic_blocks_long <- genetic_blocks_df %>%
  pivot_longer(-p, names_to = "GeneticBlocks", values_to = "Probability")

# Set color palette for plot
my.cols2 <- wes_palette("FantasticFox1")[3:5]

# Create the ggplot2 plot
ggplot_genetic_blocks <- ggplot(genetic_blocks_long, aes(x = p, y = Probability, color = GeneticBlocks, group = GeneticBlocks)) +
  geom_point() +
  geom_line(size = 2) +
  scale_color_manual(values = my.cols2,
                     labels = c("Cousins (w. >0 genomic blocks)",
                                "Cousins (w. >1 genomic blocks)",
                                "Cousins (w. >2 genomic blocks)"),
                     name = "Type of Cousin") +
  labs(x = "p (degree of cousin)", y = "Probability p-th cousin \"detectable\"") +
  theme_minimal() +
  scale_x_continuous(breaks = 1:8) + # Show every value from 1 to 8 on the x-axis
  scale_y_continuous(limits = c(0, 1)) # Set y-axis limits to 0 and 1

# Display the plot
ggplot_genetic_blocks

```


### Relative to database size

```{r df-numgen-cousins-db}
calc_numgen_cousins_df <- function(p, DB.sizes, N, prob) {
  pop_columns <- N[, -1, drop = FALSE]
  results_df <- tibble(Population = character(), p.degree = numeric(), DB.size = numeric(), Num_Cousins = numeric())

  for (pop_name in colnames(pop_columns)) {
    pop_vector <- pop_columns[[pop_name]]

    for (db_size in DB.sizes) {
      num_cousins <- 4^(p) * db_size / (pop_vector / 2)
      gen_related_cousins <- num_cousins * prob

      results_df <- rbind(results_df, tibble(Population = pop_name, p.degree = p, DB.size = db_size, Num_Cousins = gen_related_cousins))
    }
  }

  return(results_df)
}


plt_numgen_cousins_df <- calc_numgen_cousins_df(p, DB.sizes, N, prob.g.e.3.blocks) %>% 
  mutate(Population = factor(Population,
                             levels = c("Black", "White", "Total", "Coop")))
```

```{r plt-numgen-cousins-db, fig.cap= "Expected number of genetic p-th cousins in databases of varying sizes for different populations. Each panel represents a population, and the lines within each panel correspond to different database sizes"}
plt_numgen_cousins <- function(data, my.cols) {
  plot <- ggplot(data, aes(x = p.degree, y = Num_Cousins, color = factor(DB.size), group = factor(DB.size))) +
    geom_point() +
    geom_line() +
    scale_color_manual(values = my.cols, name = "Database size\n(Millions)",
                       labels = format(unique(data$DB.size) / 1e6, dig = 1)) +
    labs(x = "p (degree of cousin)", y = "Expected number of genetic p-th cousins in database") +
    theme_minimal() +
    facet_wrap(~ Population, labeller = labeller(Population = as_labeller(function(x) x))) +
    scale_x_continuous(breaks = 1:8) # Show every value from 1 to 8 on the x-axis

  return(plot)
}


plt_numgen_cousins(plt_numgen_cousins_df, my.cols)


```

```{r}
predict_total_simulations <- function(n_sims_unrelated, n_sims_related) {
  unique_populations <- 4
  relationship_types <- 6  # Includes parent_child, full_siblings, half_siblings, cousins, second_cousins, unrelated

  # Calculate total number of observations
  total_simulations <- unique_populations *
                       (n_sims_unrelated + (relationship_types - 1) * n_sims_related) 
  
  total_observations <- total_simulations * relationship_types

  cat("Total number of simulations =", total_simulations, "\n")
  cat("Total number of observations in csv =", total_observations, "\n")
}
```

```{r}

predict_total_simulations(100000, 10000)

```

```{r}
input_df <- read_csv("data/dl_known_vs_tested_simulation_results.csv") %>% 
  mutate(log_R_sum = ifelse(is.infinite(log_R_sum) & log_R_sum < 0,
                            log(1.4e-11),
                            log_R_sum))

```


```{r}
# Check if there are any -Inf values in the log_R_sum column
inf_values_log_R_sum <- sapply(input_df$log_R_sum, function(x) is.infinite(x) & x < 0)

# Count the number of rows containing -Inf values
num_rows_with_inf <- sum(inf_values_log_R_sum)

# Print the count of rows containing -Inf values in log_R_sum
print(paste("Number of rows with -Inf values in log_R_sum column:", num_rows_with_inf))


```



```{r}
# Filter the input dataframe for unrelated values only
input_df_unrelated <- input_df %>% filter(known_relationship_type == "unrelated")
```

```{r}
# input_df <- read_csv("data/jvc-known_vs_tested_simulation_results.csv") 
```


```{r}
# Function to calculate proportion exceeding cutoff
calculate_proportion_exceeding_cutoff <- function(input_population, relationship_type, fp_rate, input_df) {

  unrelated_tested <- input_df %>%
    filter(population == input_population,
           known_relationship_type == "unrelated",
           tested_relationship_type == relationship_type)
  
  m_value = fp_rate / 100
  cut_value <- quantile(unrelated_tested$log_R_sum, 1 - m_value)
  
  actual_relationship <- input_df %>%
    filter(population == input_population,
           known_relationship_type == relationship_type,
           tested_relationship_type == relationship_type)
  
  proportion_exceeding_cutoff <- mean(actual_relationship$log_R_sum > cut_value)
  
  return(data.frame(population = input_population,
                    relationship_type = relationship_type,
                    fp_rate = fp_rate,
                    prop_exceeding = proportion_exceeding_cutoff))
}

# Define a vector of false positive rates as percentages
fp_rates <- c(1, 5, 10)

population_groups = unique(input_df$population)
relationship_types = unique(input_df$known_relationship_type)

# Exclude "unrelated" from relationship types for calculation purposes
relationship_types = relationship_types[relationship_types != "unrelated"]

# Apply function to calculate proportions for each combination of population group, relationship type and false positive rate
proportion_args <- expand.grid(input_population = population_groups, 
                               relationship_type = relationship_types,
                               fp_rate = fp_rates)

# add input_df for each row
proportion_args$input_df <- I(rep(list(input_df), nrow(proportion_args)))

exceeding_proportions <- purrr::pmap_df(proportion_args,
                                        calculate_proportion_exceeding_cutoff)

# Look at the results
exceeding_proportions

```

```{r}

# Convert population to factor so it can be used in fill aesthetic
exceeding_proportions$population <- as.factor(exceeding_proportions$population)

# Calculate the total number of unrelated pairs and full sibling pairs
num_pairs <- input_df %>% 
  group_by(population, known_relationship_type) %>%
  summarise(n_pairs = n()) %>% 
  spread(known_relationship_type, n_pairs, fill = 0)

# Take the values from the first population
first_population <- num_pairs$population[1]
num_unrelated_pairs <- num_pairs$unrelated[1]
num_related_pairs <- num_pairs$full_siblings[1] 

# format numbers with comma as thousands separator
num_unrelated_pairs <- format(num_unrelated_pairs, big.mark = ",")
num_related_pairs <- format(num_related_pairs, big.mark = ",")

# Create the caption
caption_text <- paste("Number of unrelated pairs per population: ", num_unrelated_pairs,
                      ". Number of related pairs: ", num_related_pairs, ".")

# Create the facetted bar plot
ggplot(exceeding_proportions, aes(x = relationship_type, y = prop_exceeding, fill = population)) +
  geom_bar(stat = "identity", position=position_dodge()) +
  facet_wrap(~fp_rate, scales="free") +
  scale_fill_manual(values = wes_palette("Darjeeling1", n = length(unique(exceeding_proportions$population)), type = "continuous")) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylab("Proportion exceeding cut-off") +
  xlab("Relationship type") +
  ggtitle("Proportions exceeding likelihood cut-off for different relationship types") +
  labs(fill = "Population") +
  labs(caption = caption_text)
```

